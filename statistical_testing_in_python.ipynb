{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Statistical Testing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Python is a powerful, general purpose, language that is widely used in data science, R is a domain-specific language designed for statistical analysis. Its libraries are often released by researchers and the documentation and code is accompanied by citations from scientific papers. The application of statistical formulas are much simplier with R language and the outputs tend to be more informative than their counterparts in Python (although there are packages in Python that can provide a similar framework to R, i.e. statsmodels). \n",
    "\n",
    "The purpose of this project is to demonstrate through examples how one can apply statistical testing in Python using only SciPy.stats to achieve the similar functionality as R. \n",
    "\n",
    "### Contents\n",
    "\n",
    "<ul>\n",
    "  <li>1. Parametric (Normal Distribution) Testing:   \n",
    "    <ul>\n",
    "      <li>1.1 Comparing Two Groups:\n",
    "        <ul>\n",
    "          <li>1.1.1 Unpaired: sample t-tests</li>\n",
    "          <li>1.1.2 Paired: paired t-test</li>\n",
    "          <li>1.1.3 Chi-square test for variance</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>1.2 Comparing More than Two Groups:\n",
    "        <ul>\n",
    "          <li>1.2.1 Sample design: one way ANOVA</li>\n",
    "          <li>1.2.2 Block design: two way ANOVA</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "     </ul>\n",
    "    </li>\n",
    "    <li>2. Non-Parametric (Non-Normal Distribution) Testing:   \n",
    "      <ul>\n",
    "        <li>2.1 Comparing Two Groups:\n",
    "           <ul>\n",
    "             <li>2.1.1 Unpaired: Wilcoxon rank-sum test</li>\n",
    "             <li>2.1.2 Paired: Wilcoxon signed-rank test </li>\n",
    "           </ul>\n",
    "        </li>\n",
    "        <li>2.2 Comparing More than Two Groups:\n",
    "           <ul>\n",
    "             <li>2.2.1 Sample design: Kruskal-Wallis test</li>\n",
    "             <li>2.2.2 Block design: Friedman test</li>\n",
    "           </ul>\n",
    "        </li>\n",
    "      </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parametric (Normal Distribution) Testing\n",
    "\n",
    "Parametric tests makes assumptions of the underyling distribution of the data. These assumptions must be met for the tests to be considered reliable. For example, for a paired t-test for two samples, the test is considered reliable only if both samples follow a normal distribution and have the same variances. \n",
    "\n",
    "## 1.1 Comparing Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ttest_ind, ttest_1samp, ttest_rel, chisquare, chi2, t\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpaired Sample t-tests\n",
    "    \n",
    "<b> One sample, two tailed t-test</b> \n",
    "\n",
    "A one sample, two tailed t-tests determines whether the sample mean is statistically different from a known or hypothesized population mean. For this scenerio, SciPy's \"ttest_1samp\" function is used.\n",
    "\n",
    "Example 1: Test with a 95 percent confidence interval whether the volume of a shipment of lumber is as per usual the 39,000 cubic feet. Suppose the shipment mean is 36,500 cubic feet with a standard deviation of 2,000. So the null hypothesis is Ho: mu = 39000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 36507.58517 std: 1987.60671\n"
     ]
    }
   ],
   "source": [
    "data_mean = 36500\n",
    "data_std = 2000\n",
    "\n",
    "data = np.random.normal(loc=data_mean, scale=data_std, size=75)\n",
    "print ('mean: %.5f' % data.mean(), 'std: %.5f' % data.std(ddof=1))\n",
    "# Note: R calulates the standard deviation with N - 1 as the denominator, and numpy with N. \n",
    "# To get identical results, set ddof = 1 (\"delta degrees of freedom\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-10.859766890351752, pvalue=5.662451054667056e-17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_1samp(data, 39000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this above example, the p-value is greater than 0.05, we cannot reject the null hypothesis that the sample mean is equal to the population mean. We can also define a function to output a message advising whether to reject the null hypothesis at a specified confidence level (i.e. 0.1, 0.05, 0.01).\n",
    "\n",
    "Example 2: The results obtained for an intelligence test in 10 subjects are: 65, 78, 88, 55, 48, 95, 66, 57, 79, 81. Test with a 99% confidence interval that the population which received the same test is equal to 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 71.20000 std: 15.34637\n"
     ]
    }
   ],
   "source": [
    "results = np.array([65,78,88,55,48,95,66,57,79,81])\n",
    "print ('mean: %.5f' % results.mean(), 'std: %.5f' % results.std(ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample_two_tailed(data, pop_mean, alpha):\n",
    "    t, p = ttest_1samp(data, pop_mean)\n",
    "    print ('t: %.5f' % t)\n",
    "    print ('p: %.5f' % p)\n",
    "    if p < alpha:\n",
    "        print('P-Value is less than alpha: We can reject the null hypothesis')\n",
    "    if p > alpha:\n",
    "        print('P-value is greater than alpha: We cannot reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: -0.78303\n",
      "p: 0.45372\n",
      "P-value is greater than alpha: We cannot reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "one_sample_two_tailed(results, 75, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> One Sample, one tailed t-test</b> \n",
    "\n",
    "A one sample, one tailed t-tests determines whether the sample mean is greater or less than a known or hypothesized population mean. The t.test function in R allows you to specify the upper or lower tail with the \"alternaitve\" parameter. However, the ttest_1samp has no such functionality. We can define a function with a similar parameter which take in 'less' or 'greater' as the alternative hypothesis. \n",
    "\n",
    "Example 1: A bottle filling machine is set to fill bottles with a volume of 500 ml, which the actual volume known to follow a normal distribution. The manufacturer believes the machine is under-filling bottles so a sample of 20 filled bottles is taken and the volume in each was recorded as: 484.11, 459.49, 471.38, 512.01, 494.48, 528.63, 493.64, 485.03, 473.88, 501.59, 502.85, 538.08, 465.68, 495.03, 475.32, 529.41, 518.13, 464.32, 449.08, 489.27.\n",
    "\n",
    "Use a one-sample t-test to determine whether the bottles are being under filled using a significance level of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 491.57050 std: 24.79368\n"
     ]
    }
   ],
   "source": [
    "volume = np.array([484.11, 459.49, 471.38, 512.01, 494.48, 528.63, 493.64, 485.03, 473.88, 501.59, 502.85, 538.08, 465.68, 495.03, 475.32, 529.41, 518.13, 464.32, 449.08, 489.27])\n",
    "print ('mean: %.5f' % volume.mean(), 'std: %.5f' % volume.std(ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function defines a one sample one tailed test based off the following intuition:\n",
    "\n",
    "- Suppose the alternative hypothesis is μ > 0. In this case if the sample mean is negative, we cannot reject the null that the true mean is zero in favour of the alternative that it is positive if the data suggests that the mean is negative.\n",
    "- Furthermore, a positive t-statistic implies that the sample mean is larger than the hypothesized mean.  This would be evidence against the null hypothesis IF (and only if) the alternative was that the true mean is GREATER than the hypothesized value.\n",
    "\n",
    "- Suppose the alternative hypothesis is μ < 0. If the sample mean is positive, then we cannot reject the null hypothesis that the true mean is zero in favour of the alternative that it is negative. \n",
    "- A negative t-statistic implies that the sameple mean is less than the hypothesized mean, which is evidence against the null hypothesis IF (and only if) the alternative was that the true mean is LESS than the hypothesized mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample_one_tailed(data, pop_mean, alpha, alternative):\n",
    "    t, p = ttest_1samp(data, pop_mean)\n",
    "    print('t: %.5f'% t)\n",
    "    if (t < 0 and alternative == 'less') | (t > 0 and alternative == 'greater'):\n",
    "        p = p/2\n",
    "        print('p: %.5f'% p)\n",
    "    if (t < 0 and alternative == 'greater') | (t > 0 and alternative == 'less'):\n",
    "        p = 1-(p/2)\n",
    "        print('p: %.5f'% p)\n",
    "    if p < alpha:\n",
    "        print('%.5f'% p, 'is less than', alpha, 'therefore reject null hypothesis')\n",
    "    if p > alpha:\n",
    "        print('%.5f'% p, 'is greater than', alpha, 'therefore cannot reject null hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: -1.52046\n",
      "p: 0.07243\n",
      "0.07243 is greater than 0.01 therefore cannot reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "one_sample_one_tailed(volume, 500, alpha=0.01, alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Independent Two Sample t-test</b> \n",
    "\n",
    "The two-sample t-test is used to determine if two samples means are equal. The fucntion \"ttest_ind\" is used for two sample t-tests. However, unlike R's t.test function, the output from ttest_ind does not provide the confidence intervals of the difference in means. To overcome this, two seperate functions are defined based on pooled or unpooled variances.\n",
    "\n",
    "Example 1: Assuming that the data in mtcars follows the normal distribution, find the 95% confidence interval estimate of the difference between the mean gas mileage of manual and automatic transmissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = pd.read_csv(\"https://gist.githubusercontent.com/seankross/a412dfbd88b3db70b74b/raw/5f23f993cd87c283ce766e7ac6b329ee7cc2e1d1/mtcars.csv\")\n",
    "mpg_auto = mtcars['mpg'][mtcars['am']==0]\n",
    "mpg_manual = mtcars['mpg'][mtcars['am']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-3.767123145144923, pvalue=0.0013736383330710345)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate t-test for 2 independent samples with unequal variances. \n",
    "ttest_ind(mpg_auto, mpg_manual, equal_var= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we can reject the null hypothesis that the two samples are equal. The following function calculates the 95% confidence interval for the difference between two means given unequal variances between the two samples. \n",
    "\n",
    "Note that there are two formuals to calculate the CI based on whether the variances are pooled or unpooled. The unpooled method is known as the Welch-Satterthwaite method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate 95% confidence intervals for unpooled variances \n",
    "def confit_welch_2samp(x1, x2):\n",
    "    diff_mean = x1.mean() - x2.mean()\n",
    "    N1 = x1.shape[0]\n",
    "    N2 = x2.shape[0]\n",
    "    # Degrees of Freedom\n",
    "    df = (((x1.std()**2 /N1) + (x2.std()**2 /N2))**2) / ((x1.std()**4)/((N1**2)*(N1-1)) + (x2.std()**4)/((N2**2)*(N2-1)))\n",
    "    # Standard Error\n",
    "    se = sqrt((x1.std()**2/N1) + (x2.std()**2/N2))\n",
    "    # T-value\n",
    "    t_val = t.ppf(0.975, df)\n",
    "    # Margin of Error\n",
    "    MoE = t_val * se\n",
    "    #95% Confidence Interval\n",
    "    conf_int = diff_mean - MoE, diff_mean + MoE    \n",
    "    print('95 percent confidence interval:', conf_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percent confidence interval: (-11.280194355040031, -3.2096841874700814)\n"
     ]
    }
   ],
   "source": [
    "confit_welch_2samp(mpg_auto, mpg_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that with 95% confidence the difference in mean mpg between auto and manual transmission is between -11.28 and -3.21.\n",
    "\n",
    "Example 2: Consider the weight gain of 19 rats between 28 and 84 days after birth. 12 were fed on a high protein diet and 7 on a low protein diet. Using the following data, test the hypothesis that there is no difference in weight gain between rats raised on a high-protein diet versus a low-protein diet. Use a significance level of α = 0.05 and assume equal variances. \n",
    "\n",
    "High protein: 134,146,104,119,124,161,107,83,113,129,97,12  Low protein: 70,118,101,85,107,132,94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.89143639744233, pvalue=0.07573012895667763)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_protein = np.array([134,146,104,119,124,161,107,83,113,129,97,123])\n",
    "low_protein = np.array([70,118,101,85,107,132,94])\n",
    "ttest_ind(high_protein, low_protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below formula takes in two vectors and calculates the 95% confidence interval for a difference in means assuming equal variances between both samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% confidence interval for pooled variances \n",
    "def confint_2samp(x1, x2):\n",
    "    diff_mean = x1.mean() - x2.mean()\n",
    "    N1 = x1.shape[0]\n",
    "    N2 = x2.shape[0]\n",
    "    df = N1 + N2 - 2\n",
    "    #t-statistic \n",
    "    t_val = t.ppf(0.975, df)    \n",
    "    std_N1N2 = sqrt(((N1 - 1 )*(x1.std())**2 + (N2 - 1)*(x2.std())**2) / df)\n",
    "    # Margin of Error\n",
    "    MoE = t_val * std_N1N2 * sqrt(1/N1+ 1/N2)   \n",
    "    #95% Confidence Interval\n",
    "    confint = diff_mean - MoE, diff_mean + MoE\n",
    "    print('95 percent confidence interval:', confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percent confidence interval: (-1.068489658012112, 39.06848965801211)\n"
     ]
    }
   ],
   "source": [
    "confint_2samp(high_protein, low_protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired Sample t-test \n",
    "\n",
    "The paired t-test is used to determine the difference in means between two samples for the same subject, for example the samples are seperated by time. With SciPy, the ttest_rel function is used to conduct the paired t-test. \n",
    "\n",
    "Example: In the immer dataset, Y1 represents yield in 1931, Y2 in 1932. Assuming that the data in immer follows the normal distribution, find the 95% confidence interval estimate of the difference between the mean barley yields between years 1931 and 1932."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found on GitHub\n",
    "immer = pd.read_csv(\"immer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.3239873042716788, pvalue=0.0024126338636167597)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use ttest_rel for paired samples\n",
    "ttest_rel(immer['Y1'], immer['Y2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the low p-value we can reject the null hypothesis that the mean yields in 1931 and 1932 are the same. \n",
    "\n",
    "SciPy's ttest_rel also does not output the confidence intervals. The below function calculates the CI using the formula for the paired t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confint_paired(x1, x2):\n",
    "    for i in x1, x2:\n",
    "        x_diff = x1 - x2\n",
    "        mean_diff = abs(x_diff.mean())\n",
    "        std_diff = x_diff.std()\n",
    "        se = x_diff.std() / sqrt(len(x_diff))\n",
    "        t_val = t.ppf(0.975, (len(x_diff)-1))\n",
    "        MoE = t_val * se\n",
    "        confint = mean_diff - MoE, mean_diff + MoE\n",
    "    print('95 percent confidence interval:', confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percent confidence interval: (6.121953866677087, 25.704712799989572)\n"
     ]
    }
   ],
   "source": [
    "confint_paired(immer['Y1'], immer['Y2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square Test for Variance\n",
    "\n",
    "According to Wikipedia, \"Cochran's therom shows that variance follows a scaled chi-squared distribution\".\n",
    "\n",
    "Example: A professor is convinced that her students midterm grades have a variance greater than 4. To test her hypothesis, she randomly samples 10 students' midterms results from her class. The grades recorded are the following: 72, 71, 76, 77, 78, 68, 73, 71, 78, 78. Is the professor's claim correct? Test the appropriate hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.9"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = np.array([72, 71, 76, 77, 78, 68, 73, 71, 78, 78])\n",
    "samplevariance = grades.var(ddof=1)\n",
    "popvariance = 4\n",
    "n = len(grades)\n",
    "\n",
    "# calculate the test statistic: sum of squares about the same means divided by the nominal value for the variance\n",
    "chi_sq = ((n-1)*samplevariance)/popvariance\n",
    "chi_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value: 16.918977604620448 P-value: 0.0004562434471995225\n"
     ]
    }
   ],
   "source": [
    "# calculate critical value using chi-squared distribution\n",
    "critical_val = chi2.ppf(0.95, (n-1))   \n",
    "p_value = 1 - chi2.cdf(chi_sq, (n-1))\n",
    "\n",
    "print(\"Critical value:\", crit, \"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test statistic is greater than the critical value we can reject the null hypothesis that the variance equals to 4. Alternatively because the p-value is less than the alpha value of 0.05, we can reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Comparing More than Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Design: One-way ANOVA\n",
    "\n",
    "The ANOVA F-test is used to analyze the difference in population means between two or more groups. With SciPy, f_oneway is used to perform a one-way ANOVA. The following example contains 3 groups (treatments) with 7 observations per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = [18.2, 20.1, 17.6, 16.8, 18.8, 19.7, 19.1]\n",
    "group_2 = [17.4, 18.7, 19.1, 16.4, 15.9, 18.4, 17.7]\n",
    "group_3 = [15.2, 18.8, 17.7, 16.5, 15.9, 17.1, 16.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=3.968295753691201, pvalue=0.037345340805819825)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-way ANOVA on the three treatments. \n",
    "f_oneway(group_1,group_2,group_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-statistic is 3.97 and the p-value is 0.037345. We can reject the null hypothesis that the three groups have equal means.\n",
    "\n",
    "Although we know that there is a signficant difference among the three means, we don't have information on how exactly they differ. We can reject the null that all means are the same but if wish to know which means cause that difference, additional analysis will be required. For that task, we can perform a pairwise t-test to generate the pair-wise comparisons between group means with corrections for multiple testing.\n",
    "\n",
    "Example 2: Investigate into whether different methods of ventilation during anesthesia has any effect on the red folates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folate</th>\n",
       "      <th>ventilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>354</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>392</td>\n",
       "      <td>N2O+O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>206</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>210</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>226</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>249</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>255</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>273</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>285</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>295</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>309</td>\n",
       "      <td>N2O+O2,op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>241</td>\n",
       "      <td>O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>258</td>\n",
       "      <td>O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>270</td>\n",
       "      <td>O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>293</td>\n",
       "      <td>O2,24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>328</td>\n",
       "      <td>O2,24h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    folate ventilation\n",
       "0      243  N2O+O2,24h\n",
       "1      251  N2O+O2,24h\n",
       "2      275  N2O+O2,24h\n",
       "3      291  N2O+O2,24h\n",
       "4      347  N2O+O2,24h\n",
       "5      354  N2O+O2,24h\n",
       "6      380  N2O+O2,24h\n",
       "7      392  N2O+O2,24h\n",
       "8      206   N2O+O2,op\n",
       "9      210   N2O+O2,op\n",
       "10     226   N2O+O2,op\n",
       "11     249   N2O+O2,op\n",
       "12     255   N2O+O2,op\n",
       "13     273   N2O+O2,op\n",
       "14     285   N2O+O2,op\n",
       "15     295   N2O+O2,op\n",
       "16     309   N2O+O2,op\n",
       "17     241      O2,24h\n",
       "18     258      O2,24h\n",
       "19     270      O2,24h\n",
       "20     293      O2,24h\n",
       "21     328      O2,24h"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_cell_folate = pd.read_csv(\"red_cell_folate.csv\")\n",
    "red_cell_folate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=3.7113359882669763, pvalue=0.043589334959178244)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract treatments from dataframe as lists\n",
    "ventilation_1 = list(red_cell_folate[(red_cell_folate['ventilation']=='N2O+O2,24h')]['folate'])\n",
    "ventilation_2 = list(red_cell_folate[(red_cell_folate['ventilation']=='N2O+O2,op')]['folate'])\n",
    "ventilation_3 = list(red_cell_folate[(red_cell_folate['ventilation']=='O2,24h')]['folate'])\n",
    "\n",
    "# Pass in lists to f_oneway\n",
    "f_oneway(ventilation_1,ventilation_2,ventilation_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.0436 so we can reject the null hypothesis that the three groups have equal means. \n",
    "\n",
    "Note that the f_oneway() function required the sample measurements to be in the form of two or more arrays. However in real-world cases, the treatments are typically found as labels in categorical data (as per the example below). In R, the anova() function allows you to pass in dataframe columns in the form of a linear model formula, e.g. <i>lm(response~treatment)</i>. \n",
    "\n",
    "In Python when data is presnted in this form, some preprocessing would be required for compatability with the f_oneway() function. Two different approaches are demonstrated below on how to pass dataframe columns to f_oneway.\n",
    "\n",
    "Example 3: From the juul dataset, investigate into whether Tanner levels have any significant effect on amount of insulin-like growth factor, igf1. In this problem, The various Tanner levels are the treatments, and the response that we wish to test on is igf1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  menarche  sex   igf1  tanner  testvol\n",
      "0       NaN       NaN  NaN   90.0     NaN      NaN\n",
      "1       NaN       NaN  NaN   88.0     NaN      NaN\n",
      "2       NaN       NaN  NaN  164.0     NaN      NaN\n",
      "3       NaN       NaN  NaN  166.0     NaN      NaN\n",
      "4       NaN       NaN  NaN  131.0     NaN      NaN\n",
      "5      0.17       NaN  1.0  101.0     1.0      NaN\n",
      "6      0.17       NaN  1.0   97.0     1.0      NaN\n",
      "7      0.17       NaN  1.0  106.0     1.0      NaN\n",
      "8      0.17       NaN  1.0  111.0     1.0      NaN\n",
      "9      0.17       NaN  1.0   79.0     1.0      NaN\n",
      "10     0.17       NaN  1.0   43.0     1.0      NaN\n",
      "11     0.17       NaN  1.0   64.0     1.0      NaN\n",
      "12     0.25       NaN  1.0   90.0     1.0      NaN\n",
      "13     0.25       NaN  1.0  141.0     1.0      NaN\n",
      "14     0.42       NaN  1.0   42.0     1.0      NaN\n",
      "15     0.50       NaN  1.0   43.0     1.0      NaN\n",
      "16     0.67       NaN  1.0  132.0     1.0      NaN\n",
      "17     0.75       NaN  1.0   43.0     1.0      NaN\n",
      "18     0.75       NaN  1.0   36.0     1.0      NaN\n",
      "19     1.00       NaN  1.0   86.0     1.0      NaN\n",
      "20     1.16       NaN  1.0   44.0     1.0      NaN\n",
      "21     1.50       NaN  1.0   68.0     1.0      NaN\n",
      "22     1.50       NaN  1.0   89.0     1.0      NaN\n",
      "23     1.58       NaN  1.0  101.0     1.0      NaN\n",
      "24     1.67       NaN  1.0  115.0     1.0      NaN\n",
      "25     1.67       NaN  1.0   53.0     1.0      NaN\n",
      "26     1.75       NaN  1.0   94.0     1.0      NaN\n",
      "27     1.83       NaN  1.0   95.0     1.0      NaN\n",
      "28     1.92       NaN  1.0   76.0     1.0      NaN\n",
      "29     2.00       NaN  1.0   79.0     1.0      NaN\n",
      "...     ...       ...  ...    ...     ...      ...\n",
      "1309  40.08       2.0  2.0  200.0     NaN      NaN\n",
      "1310  40.91       2.0  2.0  220.0     NaN      NaN\n",
      "1311  41.00       2.0  2.0  233.0     NaN      NaN\n",
      "1312  41.43       2.0  2.0  206.0     NaN      NaN\n",
      "1313  41.91       2.0  2.0  331.0     5.0      NaN\n",
      "1314  42.00       2.0  2.0  169.0     NaN      NaN\n",
      "1315  42.69       2.0  2.0  130.0     NaN      NaN\n",
      "1316  43.10       2.0  2.0  262.0     NaN      NaN\n",
      "1317  43.33       2.0  2.0  100.0     5.0      NaN\n",
      "1318  43.80       2.0  2.0  249.0     NaN      NaN\n",
      "1319  44.62       2.0  2.0  170.0     5.0      NaN\n",
      "1320  45.22       2.0  2.0  156.0     NaN      NaN\n",
      "1321  45.28       2.0  2.0  251.0     NaN      NaN\n",
      "1322  45.41       2.0  2.0  220.0     NaN      NaN\n",
      "1323  47.00       2.0  2.0  174.0     NaN      NaN\n",
      "1324  47.37       2.0  2.0  144.0     5.0      NaN\n",
      "1325  48.01       2.0  2.0  154.0     5.0      NaN\n",
      "1326  48.34       2.0  2.0    NaN     NaN      NaN\n",
      "1327  49.46       2.0  2.0  140.0     NaN      NaN\n",
      "1328  51.07       2.0  2.0  187.0     5.0      NaN\n",
      "1329  52.00       2.0  2.0  140.0     NaN      NaN\n",
      "1330  53.18       2.0  2.0  252.0     NaN      NaN\n",
      "1331  54.00       2.0  2.0  124.0     NaN      NaN\n",
      "1332  54.00       2.0  2.0  187.0     NaN      NaN\n",
      "1333  58.95       2.0  2.0  218.0     5.0      NaN\n",
      "1334  60.99       2.0  2.0  226.0     5.0      NaN\n",
      "1335  62.73       2.0  2.0    NaN     NaN      NaN\n",
      "1336  65.00       2.0  2.0  106.0     NaN      NaN\n",
      "1337  67.88       2.0  2.0  217.0     NaN      NaN\n",
      "1338  75.12       2.0  2.0  135.0     NaN      NaN\n",
      "\n",
      "[1339 rows x 6 columns]\n",
      "tanner catergories: [nan  1.  2.  3.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "juul = pd.read_csv(\"juul.csv\")\n",
    "print(juul)\n",
    "# View treatments\n",
    "print('tanner catergories:', juul['tanner'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach is to iterate through the unique values in the treatment column and for each treatment, select the values from the response column. The list of lists will then expand and can be passed into the f_oneway function as individual arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=228.35305434880294, pvalue=4.67821313278659e-130)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_oneway(*[group['igf1'].values for name, group in juul[(juul['igf1'].notnull())].groupby('tanner')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high p-value there is not enough evidence to reject the null hypothesis that there is any difference in igf1 between the various tanner levels. \n",
    "\n",
    "The next alternative is to create a dictionary of key-value pairs for treatment and response variables to pass into f_oneway. This is useful if you wish to select and compare only a subset of the treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tanner_nan', 'tanner_1.0', 'tanner_2.0', 'tanner_3.0', 'tanner_4.0', 'tanner_5.0'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create key-value pairs of response variables for each treatment\n",
    "tanner = juul['tanner'].unique()\n",
    "d = {}\n",
    "for i in tanner:\n",
    "    d['tanner_%s' % i] = list(juul[(juul['tanner']==i) & (juul['igf1'].notnull())]['igf1'])\n",
    "\n",
    "# View labels\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=228.35305434880294, pvalue=4.67821313278659e-130)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass lists into f_oneway, we will exclude tanner_nan\n",
    "f_oneway(d['tanner_1.0'], d['tanner_2.0'], d['tanner_3.0'], d['tanner_4.0'], d['tanner_5.0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Note that the above ANOVA tests assume equal variance. Currently SciPy does not have the option to perform the Welch ANOVA test for unequal variances. This section will be updated with code to perform this task. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Design: Two-way ANOVA\n",
    "\n",
    "In block design, k treatment means are compared, and blocks are b experiemental units that are similar or homogeneous. One unit within each block is assigned to each treatment. \n",
    "\n",
    "Example: The following data frame contains data for nine patients with congestive heart failure before and shortly after administration of enalaprilat. The column 'hr' is the patient heart rate, 'subj' has the subject ids and 'time' indicates time between administration of enalaprilat and measuring the heart rate. Investigate if time or subject has any effect on the heart rates by performing a two way ANOVA. \n",
    "\n",
    "The dataframe below indicates that 'subj' are the treatments, 'time' are the blocks, and 'hr' is the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>subj</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>106</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>102</td>\n",
       "      <td>9</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hr  subj  time\n",
       "0    96     1     0\n",
       "1   110     2     0\n",
       "2    89     3     0\n",
       "3    95     4     0\n",
       "4   128     5     0\n",
       "5   100     6     0\n",
       "6    72     7     0\n",
       "7    79     8     0\n",
       "8   100     9     0\n",
       "9    92     1    30\n",
       "10  106     2    30\n",
       "11   86     3    30\n",
       "12   78     4    30\n",
       "13  124     5    30\n",
       "14   98     6    30\n",
       "15   68     7    30\n",
       "16   75     8    30\n",
       "17  106     9    30\n",
       "18   86     1    60\n",
       "19  108     2    60\n",
       "20   85     3    60\n",
       "21   78     4    60\n",
       "22  118     5    60\n",
       "23  100     6    60\n",
       "24   67     7    60\n",
       "25   74     8    60\n",
       "26  104     9    60\n",
       "27   92     1   120\n",
       "28  114     2   120\n",
       "29   83     3   120\n",
       "30   83     4   120\n",
       "31  118     5   120\n",
       "32   94     6   120\n",
       "33   71     7   120\n",
       "34   74     8   120\n",
       "35  102     9   120"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_rate = pd.read_csv('heart_rate.csv')\n",
    "heart_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently SciPy has no feature to compute a two way ANOVA. Without the help of other packages like statsmodels you will need to code it yourself to perform this task. Below is function based on the randomized block design formula. The inputs are the column names for the response, treatments and blocks, followed by data. The output is the ANOVA table similar to the output in R with the anova() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_twoway(values, treatments, blocks, data):\n",
    "    \n",
    "    # Compute correction of the means:\n",
    "    totals = []\n",
    "    for i in data[treatments].unique():\n",
    "        totals.append(data[(data[treatments]==i)][values].sum())\n",
    "        G = sum(totals)\n",
    "        CM = (G**2)/(data[blocks].nunique()*data[treatments].nunique())    \n",
    "    \n",
    "    # Compute sum of squares:\n",
    "    ss = []\n",
    "    for i in data[values]:\n",
    "        ss.append(i**2)\n",
    "        total_SS = sum(ss) - CM    \n",
    "    ss_t = []\n",
    "    for i in data[treatments].unique():\n",
    "        ss_t.append(data[(data[treatments]==i)][values].sum())\n",
    "        SST = (sum([i**2 for i in ss_t]))/(data[blocks].nunique())-CM\n",
    "    ss_b = []\n",
    "    for i in data[blocks].unique():\n",
    "        ss_b.append(data[(data[blocks]==i)][values].sum())\n",
    "        SSB = (sum([i**2 for i in ss_b]))/(data[treatments].nunique())-CM\n",
    "    SSE = total_SS - SST - SSB    \n",
    "    \n",
    "    # Compute df and mean sq:\n",
    "    df_treatment = data[treatments].nunique()-1\n",
    "    df_block = data[blocks].nunique()-1\n",
    "    df_error = df_treatment*df_block\n",
    "    MST = SST/df_treatment\n",
    "    MSB = SSB/df_block\n",
    "    MSE = SSE/df_error\n",
    "    \n",
    "    # test statistics and p-values:\n",
    "    F_treatment = MST/MSE \n",
    "    F_block = MSB/MSE\n",
    "    p_treatment = f.sf(F_treatment, df_treatment, df_error)\n",
    "    p_block = f.sf(F_block, df_block, df_error)\n",
    "    \n",
    "    # Build the ANOVA table similar to R\n",
    "    anova_table = pd.DataFrame(index=[treatments, blocks, 'Residuals'])\n",
    "    anova_table['Df'] = [df_treatment, df_block, df_error]\n",
    "    anova_table['Sum Sq'] = [SST, SSB, SSE]\n",
    "    anova_table['Mean Sq'] = [MST, MSB, MSE]\n",
    "    anova_table['F Value'] = [F_treatment, F_block, '']\n",
    "    anova_table['Pr(>F)'] = [p_treatment, p_block, '']\n",
    "    return(anova_table)\n",
    "\n",
    "# To do: update function to handle NaN values in columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Df</th>\n",
       "      <th>Sum Sq</th>\n",
       "      <th>Mean Sq</th>\n",
       "      <th>F Value</th>\n",
       "      <th>Pr(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subj</th>\n",
       "      <td>8</td>\n",
       "      <td>8966.555556</td>\n",
       "      <td>1120.819444</td>\n",
       "      <td>90.6391</td>\n",
       "      <td>4.86268e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>3</td>\n",
       "      <td>150.972222</td>\n",
       "      <td>50.324074</td>\n",
       "      <td>4.06964</td>\n",
       "      <td>0.0180205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residuals</th>\n",
       "      <td>24</td>\n",
       "      <td>296.777778</td>\n",
       "      <td>12.365741</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Df       Sum Sq      Mean Sq  F Value       Pr(>F)\n",
       "subj        8  8966.555556  1120.819444  90.6391  4.86268e-16\n",
       "time        3   150.972222    50.324074  4.06964    0.0180205\n",
       "Residuals  24   296.777778    12.365741                      "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_twoway('hr', 'subj', 'time', heart_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is identical to the output given by R's anova() function. From the low p-values, we can reject the null hypothesis that the mean heartrate is the same between subjects and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Non-Parametric (Non-Normal Distribution) Testing\n",
    "\n",
    "Non-parametric tests do not make any assumptions with respect to the underlying distribution of the data, i.e. it does not assume data is normally distributed or have the same variance. The data cannot be measured quantitatively therefore measurements will be done through ranking. \n",
    "\n",
    "## 2.1 Comparing Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums, wilcoxon, mannwhitneyu, rankdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon Rank Sum Test\n",
    "\n",
    "The Wilcoxon Rank Sum Test is the rank equivalent of the unpaired t-test. In SciPy, the ranksums function computes the Wilcoxon rank-sum statistic for two samples. However ranksums is unable to handle ties in ranks between two samples. In this case, the mannwhitneyu function is more appropriate. \n",
    "\n",
    "Example: A data science student is using two machine learning algorithms to analyze a given dataset. First she tests her model with a Decision Tree using a 10-fold Cross Validation and records the Accuracy for each fold. She then repeats using a 12-fold Logistic Regression algorithm on the same dataset. The accuracy for each fold of the algorithms are given as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = [75, 79, 69, 78, 65, 87, 74, 81, 77, 88]\n",
    "LR = [85, 68, 78, 73, 69, 76, 69, 80, 73, 67, 78, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=73.0, pvalue=0.40861810325767045)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(DT, LR, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since p-value > 0.05 we do not reject the null hypothesis that both algorithms perform similarily. 73 is the the statistic for the Mann Whitney U Test (denoted by U). According to R documentation for its wilcox.test, the statistic computed for the rank sum test is also the U statistic, despite having the label 'W'. \n",
    "\n",
    "To calculate the W statistic manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 is 128.0\n",
      "T1* is 102.0\n",
      "T is 102.0\n"
     ]
    }
   ],
   "source": [
    "def sum_rank_statistic (x, y):\n",
    "    \n",
    "    n = ['n1' for i in range(len(x))] + ['n2' for i in range(len(y))]\n",
    "    rank = list(rankdata(x + y, method='average')) # rank all observations and average the tied elements\n",
    "    \n",
    "    if x < y:  # The smaller sample size is used for 'n1'\n",
    "        T1 = sum([rank for n, rank in zip(n, rank) if n=='n1']) # sum the ranks for n1\n",
    "        T1_ = len(x)*(len(x + y)+1) - T1 # calcualte n1(n1+n2+1)-T1\n",
    "    else:\n",
    "        T1 = sum([rank for n, rank in zip(n, rank) if n=='n2']) \n",
    "        T1_ = len(y)*(len(x + y)+1) - T1\n",
    "    \n",
    "    T = min(T1, T1_) # min of T1 and T1*\n",
    "    \n",
    "    print(\"T1 is\", T1)\n",
    "    print('T1* is', T1_)\n",
    "    print('T is', T)\n",
    "    \n",
    "sum_rank_statistic(DT, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1 is the test statistic for a left-tailed test, T1* is used for a right-tailed test, and T= min(T1,T1*) for a two-tailed test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon Signed-Rank Test\n",
    "\n",
    "The Wilcoxon signed-rank test is the rank equivalent of the paired t-test and is used when the data is non-parametric and both samples are paired. The wilcoxon() function from SciPy is used to conduct the signed-rank test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: The manager of a park wants to see if pollution levels in the lake are reduced when boats are not allowed. This is measured by the rate of pollution every 60 minutes for a day when boats are allowed, and a seperate day when they are not. Below are the measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [159, 135, 141, 101, 102, 168, 62, 167, 174, 159, 66, 118, 181, 171, 112]\n",
    "b = [214, 159, 169, 202, 103, 119, 200, 109, 132, 142, 194, 104, 219, 119, 234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=40.0, pvalue=0.2680667604057142)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(a, b, correction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not enough evidence to reject the null hypothesis that the populations levels are different between both days.\n",
    "\n",
    "Note that the documentation for the wilcoxon() states, <i> \"Use only when the number of observation in each sample is > 20\". </i> This is because SciPy uses a normal approximation when calculating the p-value which works for large samples sizes, however the p-value can differ from the exact p-value for smaller samples like in this example. In contrast R's wilcox.test() function will always calculate the exact P-value unless specified for samples less than 50. \n",
    "\n",
    "To calculate the test statistics manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T+ is 40.0\n",
      "T- is 80.0\n",
      "T is 40.0\n"
     ]
    }
   ],
   "source": [
    "def signed_rank_statistic(x, y):\n",
    "\n",
    "    d = [x - y for x, y in zip(x, y)] # Find the difference in the values in both lists\n",
    "    rank = rankdata([abs(i) for i in d], method='average') # rank the absolute values of the differences\n",
    "\n",
    "    T_pos = sum([rank for d, rank in zip(d, rank) if d > 0]) # sum all ranks where differences are postive\n",
    "    T_neg = sum([rank for d, rank in zip(d, rank) if d < 0]) # \" \" \" \" negative\n",
    "    T = min(T_pos, T_neg) # min of T_pos and T_neg\n",
    "\n",
    "    print(\"T+ is\", T_pos)\n",
    "    print('T- is', T_neg)\n",
    "    print('T is', T)\n",
    "    \n",
    "signed_rank_statistic(Zip, Tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T- is the test statistic for a one-tailed test, T=min(T+,T-) is the test statistic for a two-tailed test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Comparing More than Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal, friedmanchisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal-Wallis Test \n",
    "\n",
    "The Kruskal-Wallis H test is the non-parametric, rank-based equivalent of the one-way ANOVA test. It can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable. The hypotheses for the test are: H0: population medians are equal and H1: population medians are not equal. The kruskal() function from SciPy is used to perform the Kruskal-Wallis test. \n",
    "\n",
    "Like the f_oneway(), the kruskal() function (and friedmanchisquare() below) takes in two or more arrays as the sample measurements to be compared. In R, the kruskal.test() function allows you to pass in dataframe columns as a formula, e.g. <i>kruskal.test(response~group)</i>, which is more applicable to real-world applications. To preprocess the data for compatibility with the kruskal() function, we use the same two approaches from the f_oneway() example.\n",
    "\n",
    "Example: Suppose data for the wages between three groups are given in the following form and we would like to determine if there is any difference in the mean wages between the three groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salary     group\n",
       "0       45       men\n",
       "1       55       men\n",
       "2       60       men\n",
       "3       70       men\n",
       "4       72       men\n",
       "5       23     women\n",
       "6       41     women\n",
       "7       54     women\n",
       "8       66     women\n",
       "9       90     women\n",
       "10      20  minority\n",
       "11      30  minority\n",
       "12      34  minority\n",
       "13      40  minority\n",
       "14      44  minority"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = [45, 55, 60, 70, 72, 23, 41, 54, 66, 90, 20, 30, 34, 40, 44]\n",
    "group = ['men' for i in range(5)]+['women' for i in range(5)]+['minority' for i in range(5)]\n",
    "wages = pd.DataFrame({'salary': salary, 'group': group})\n",
    "wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=6.720000000000006, pvalue=0.03473525894473845)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kruskal(*[group['salary'].values for name, group in wages.groupby('group')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=6.720000000000006, pvalue=0.03473525894473845)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for i in wages['group'].unique():\n",
    "    d['group_%s' % i] = list(wages[(wages['group']==i)]['salary'])\n",
    "    \n",
    "kruskal(d['group_men'],d['group_women'],d['group_minority'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friedman Test\n",
    "\n",
    "The Friedman test is the rank equivalent of the randomized block design with k treatments and b blocks. All K measuresments within a block are ranked. Sums of the ranks of the k observations are then used to compare the k treatment distributions. The SciPy function for the Friedman test is friedmanchisquare().\n",
    "\n",
    "\n",
    "Example: A student is using three machine learning algorithms to analyze a given dataset. She tests her model using the Decision Tree, Logistic Regression and Naive Bayes algorithm. She uses 10-fold Cross Validation by dividing her dataset into 10 parts. Nine of those parts are use for training and one tenth for testing. She repeats this procedure 10 times - each time reserving a different tenth for testing. The accuracy for each fold of the algorithms are given as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Testnames</th>\n",
       "      <th>Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>DT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>DT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>DT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>DT</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87</td>\n",
       "      <td>DT</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74</td>\n",
       "      <td>DT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81</td>\n",
       "      <td>DT</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>DT</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85</td>\n",
       "      <td>DT</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>85</td>\n",
       "      <td>LR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>68</td>\n",
       "      <td>LR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>78</td>\n",
       "      <td>LR</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>73</td>\n",
       "      <td>LR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>69</td>\n",
       "      <td>LR</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>76</td>\n",
       "      <td>LR</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>69</td>\n",
       "      <td>LR</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>LR</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73</td>\n",
       "      <td>LR</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>67</td>\n",
       "      <td>LR</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>86</td>\n",
       "      <td>NB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>75</td>\n",
       "      <td>NB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>79</td>\n",
       "      <td>NB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>82</td>\n",
       "      <td>NB</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68</td>\n",
       "      <td>NB</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>69</td>\n",
       "      <td>NB</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>77</td>\n",
       "      <td>NB</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>81</td>\n",
       "      <td>NB</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>NB</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>79</td>\n",
       "      <td>NB</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy Testnames  Folds\n",
       "0         75        DT      1\n",
       "1         79        DT      2\n",
       "2         69        DT      3\n",
       "3         78        DT      4\n",
       "4         65        DT      5\n",
       "5         87        DT      6\n",
       "6         74        DT      7\n",
       "7         81        DT      8\n",
       "8         77        DT      9\n",
       "9         85        DT     10\n",
       "10        85        LR      1\n",
       "11        68        LR      2\n",
       "12        78        LR      3\n",
       "13        73        LR      4\n",
       "14        69        LR      5\n",
       "15        76        LR      6\n",
       "16        69        LR      7\n",
       "17        80        LR      8\n",
       "18        73        LR      9\n",
       "19        67        LR     10\n",
       "20        86        NB      1\n",
       "21        75        NB      2\n",
       "22        79        NB      3\n",
       "23        82        NB      4\n",
       "24        68        NB      5\n",
       "25        69        NB      6\n",
       "26        77        NB      7\n",
       "27        81        NB      8\n",
       "28        80        NB      9\n",
       "29        79        NB     10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = [75, 79, 69, 78, 65, 87, 74, 81, 77, 85]\n",
    "LR = [85, 68, 78, 73, 69, 76, 69, 80, 73, 67]\n",
    "NB = [86, 75, 79, 82, 68, 69, 77, 81, 80, 79]\n",
    "testnames = np.repeat(['DT','LR','NB'], 10)\n",
    "folds = list(range(1,11))*3\n",
    "TestModel = pd.DataFrame({'Accuracy': DT+LR+NB, 'Testnames': testnames, 'Folds': folds})\n",
    "TestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=4.6666666666666785, pvalue=0.09697196786440448)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friedmanchisquare(*[group['Accuracy'].values for name, group in TestModel.groupby('Testnames')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=4.6666666666666785, pvalue=0.09697196786440448)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for i in TestModel['Testnames'].unique():\n",
    "    d[i] = list(TestModel[(TestModel['Testnames']==i)]['Accuracy'])\n",
    "\n",
    "friedmanchisquare(d['DT'],d['LR'],d['NB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is >0.05 hence we do not reject the Null Hypothesis. \n",
    "We do not have enough evidence to suggest that any ML algorithm is better in accuracy compared to the others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
